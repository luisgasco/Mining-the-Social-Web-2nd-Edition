{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Preparing submission file and run evaluation\n",
        "\n",
        "In this notebook, a step-by-step tutorial is provided for preparing the submission file for the Task A of TalentCLEF 2026 shared task. To achieve this, the data for Task A, hosted on [Zenodo](https://doi.org/10.5281/zenodo.17625261), will be downloaded; a file with the appropriate [submission format](https://talentclef.github.io/talentclef/docs/talentclef-2026/evaluation/) will be prepared, and it will be evaluated using the [task's evaluation script](https://github.com/TalentCLEF/talentclef26_evaluation_script). Additionally, the provided format is also compatible with the Codabench benchmark where the official evaluation will be done\n",
        "\n",
        "\n",
        "-----------------------------\n",
        "TalentCLEF is an initiative to advance Natural Language Processing (NLP) in Human Capital Management (HCM). It aims to create a public benchmark for model evaluation and promote collaboration to develop fair, multilingual, and flexible systems that improve Human Resources (HR) practices across different industries.\n",
        "\n",
        "The second edition of TalentCLEF shared taskâ€™s will be part of the [Conference and Labs of the Evaluation Forum (CLEF)](https://clef2026.clef-initiative.eu/), scheduled to be held in Jena, Germany, in 2026. If you are interested in registering, you can find registration form [here](https://clef-labs-registration.dipintra.it/)\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/TalentCLEF/talentclef/blob/main/logo_talentclef.png?raw=true\" alt=\"TalentCLEF logo\" width=\"200\"/>\n",
        "<img src=\"https://talentclef.github.io/talentclef/docs/talentclef-2026/workshop/logo_clef_jena.svg\" alt=\"CLEF2026 logo\" width=\"150\"/>"
      ],
      "metadata": {
        "id": "4NXz9y-YOxuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "gHTbA4g4b5Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "bLytpvDOb6ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Task A files"
      ],
      "metadata": {
        "id": "5u2jKkACTFM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's download the Task A and Task B zip files directly from Zenodo.\n",
        "\n"
      ],
      "metadata": {
        "id": "h6dj1eCOTIN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "!wget https://zenodo.org/records/18449283/files/TaskA.zip\n",
        "!unzip TaskA.zip -d taskA"
      ],
      "metadata": {
        "id": "At8D-dYyMJDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "FPjKPVf5XagR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the environement where english dev set has been extracted:"
      ],
      "metadata": {
        "id": "53tWJv-c9rxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dev_path = \"/content/taskA/TaskA/development/en\""
      ],
      "metadata": {
        "id": "FMy0rq1v9vvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load queries and corpus elements in English from the Validation folder:"
      ],
      "metadata": {
        "id": "IcVd8_ogbyeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = os.path.join(english_dev_path, \"queries\")\n",
        "corpus_elements = os.path.join(english_dev_path, \"corpus\")"
      ],
      "metadata": {
        "id": "I5n68HKmXk9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to load data:"
      ],
      "metadata": {
        "id": "TJotZg63-DC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_corpus(path, id_col=\"c_id\", encoding=\"utf-8\"):\n",
        "    \"\"\"\n",
        "    Load text files from a directory into a pandas DataFrame.\n",
        "\n",
        "    Each file in the directory is treated as a document. The file name is used\n",
        "    as the document identifier, and the file content is stored as text.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Path to the directory containing the text files.\n",
        "    id_col : str, optional\n",
        "        Name of the column used as the document identifier\n",
        "        (e.g., 'c_id', 'q_id'). Default is 'c_id'.\n",
        "    encoding : str, optional\n",
        "        Text encoding used to read the files. Default is 'utf-8'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A DataFrame with two columns:\n",
        "        - id_col: document identifier (file name)\n",
        "        - text: document content\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "        file_path = os.path.join(path, filename)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, \"r\", encoding=encoding, errors=\"ignore\") as f:\n",
        "                text = f.read()\n",
        "\n",
        "            records.append({\n",
        "                id_col: filename,\n",
        "                \"text\": text\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "x3wcljcW-Ex5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_queries = load_text_corpus(os.path.join(english_dev_path,\"queries\"), id_col=\"q_id\")\n",
        "en_corpus = load_text_corpus(os.path.join(english_dev_path,\"corpus\"), id_col=\"c_id\")"
      ],
      "metadata": {
        "id": "pRQGDd7CYGPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "U47G-90p-QYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the list of ids and text to process:"
      ],
      "metadata": {
        "id": "xgAMRcrHCgNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries_ids = en_queries.q_id.to_list()\n",
        "queries_texts = en_queries.text.to_list()\n",
        "\n",
        "corpus_ids = en_corpus.c_id.to_list()\n",
        "corpus_texts = en_corpus.text.to_list()"
      ],
      "metadata": {
        "id": "Z3xmezhE_pa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a simple embedding model"
      ],
      "metadata": {
        "id": "01nZKPdDCkdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "OclD_jKcYSnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example, we will use a very simple approach. We will apply a basic embedding model and directly embed each document, allowing us to identify the documents in the corpus that are most similar to a given query."
      ],
      "metadata": {
        "id": "2FVBwdFfCnsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, encode queries and corpus elements"
      ],
      "metadata": {
        "id": "NHsAXWvXC-pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_embs = model.encode(queries_texts, batch_size=32)\n",
        "c_embs = model.encode(corpus_texts, batch_size=32)"
      ],
      "metadata": {
        "id": "yapzoixH-eSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, compute similarities"
      ],
      "metadata": {
        "id": "QEAeDpHZDBgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = util.cos_sim(q_embs, c_embs).cpu().numpy()"
      ],
      "metadata": {
        "id": "_LA-XVQI_ip1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare submission file"
      ],
      "metadata": {
        "id": "frtAfO3M_i7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The submissions must follow the TREC Run File format, **without** headers in the output file. This means that the fle have 6 space-spearated columns per line, with following information:\n",
        "\n",
        "- q_id: Query ID.\n",
        "- Q0: A constant identifier, usually \"Q0\".\n",
        "- doc_id: ID of the retrieved document.\n",
        "- rank: Position of the document in the ranking.\n",
        "- score: Relevance score assigned by the model.\n",
        "- tag: Experiment name"
      ],
      "metadata": {
        "id": "oeEbbK-TDFMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's process results and prepare output file. In this tutorial, we will only consider 5 relevant corpus per query."
      ],
      "metadata": {
        "id": "0gRw3kTcHuX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "results = []\n",
        "for q_idx, q_id in enumerate(queries_ids):\n",
        "    sorted_indices = np.argsort(-similarities[q_idx])  # Decrease order\n",
        "    for rank, c_idx in enumerate(sorted_indices[:5]): # For this tutorial consider only 5 relevant corpus per query\n",
        "        doc_id = corpus_ids[c_idx]\n",
        "        score = similarities[q_idx, c_idx]\n",
        "        results.append(f\"{str(q_id)} Q0 {str(doc_id)} {rank+1} {score:.4f} baseline_model\")"
      ],
      "metadata": {
        "id": "Rw7iDPch_ExR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output list have the expected structure:"
      ],
      "metadata": {
        "id": "VfCCPRRhDLTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4KR-1Df_iIL",
        "outputId": "5571409a-d42f-419f-a6bf-b8da66398ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['38671 Q0 1508 1 0.6775 baseline_model',\n",
              " '38671 Q0 24279 2 0.6637 baseline_model']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, save the list as a trec/txt file:"
      ],
      "metadata": {
        "id": "iEQJQWPEDOhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"evaluation_test_en.trec\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(results))"
      ],
      "metadata": {
        "id": "bWmOPLSy_6rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "DZBOb2Iucq5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the evaluation, we will use the official [TalentCLEF 2026 evaluation script](https://github.com/TalentCLEF/talentclef26_evaluation_script), which uses the Ranx library under the hood.\n",
        "\n",
        "First, clone the repo and install the requirements file:"
      ],
      "metadata": {
        "id": "A8l5IZancsMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TalentCLEF/talentclef26_evaluation_script.git\n",
        "!pip install -r /content/talentclef26_evaluation_script/requirements.txt\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jKr2js7xZVEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, select the Qrels file and the Run file to perform the evaluation.\n"
      ],
      "metadata": {
        "id": "iS5VMHMUdBdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels_file = \"/content/taskA/TaskA/development/en/qrels.tsv\"\n",
        "run_file = \"/content/evaluation_test_en.trec\""
      ],
      "metadata": {
        "id": "3ny9Xm2BZu0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some examples on how to use the evaluation script for different scenarios is shown in the [repo README.md](https://github.com/TalentCLEF/talentclef26_evaluation_script/blob/main/README.md#examples)."
      ],
      "metadata": {
        "id": "qCMAasl1DXPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we've been working only with english data from Task A dev set, so `--lang-mode`will be _en_, and `--task` will be _A_."
      ],
      "metadata": {
        "id": "npNg1luDDlEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "command = [\"python\", \"/content/talentclef26_evaluation_script/talentclef_evaluate.py\", \"--task\", \"A\", \"--lang-mode\", \"en\", \"--qrels\", qrels_file, \"--run\", run_file]\n",
        "result = subprocess.run(command, capture_output=True, text=True)\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "id": "sHlKBSMxZ_bB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}